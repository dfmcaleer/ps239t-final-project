{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import required modules\n",
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, read in file search_terms.csv, which has rebel groups in the\n",
    "first column, and the governments they were fighting in the second.\n",
    "This is for Google searching.  Most of the rebel groups names alone\n",
    "will not bring up their Wikipedia pages because they tend to have\n",
    "similar names to each other and/or be listed by acronyms.\n",
    "\n",
    "The value for government is usually where the conflict takes place,\n",
    "but not always (such as anti-colonial conflicts).  I tested this and\n",
    "even if the government isn't the same as the location of conflict,\n",
    "the first page to come up was always the correct one, at least for\n",
    "the ones that I tried.\n",
    "\n",
    "There are sometimes multiple entries for the same conflict.  I need\n",
    "this in the dataset for other reasons; it's not important for this\n",
    "project.  I will removed the duplicates for the visualizations later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search = []\n",
    "with open(\"search_terms.csv\", \"rU\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        search.append(row) #Loop through each row and add to list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'govt': 'Bolivia', 'group': 'Popular Revolutionary Movement'},\n",
       " {'govt': 'Bolivia', 'group': 'MNR'},\n",
       " {'govt': 'Bolivia', 'group': 'ELN'},\n",
       " {'govt': 'France', 'group': 'Khmer Issarak'},\n",
       " {'govt': 'China', 'group': 'Peoples Liberation Army'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at a chunk to make sure it's working:\n",
    "search[0:5] #So far so good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'govt': 'Bolivia', 'group': 'Popular+Revolutionary+Movement'},\n",
       " {'govt': 'Bolivia', 'group': 'MNR'},\n",
       " {'govt': 'Bolivia', 'group': 'ELN'},\n",
       " {'govt': 'France', 'group': 'Khmer+Issarak'},\n",
       " {'govt': 'China', 'group': 'Peoples+Liberation+Army'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The spaces in the group names are going to mess up the URL.\n",
    "#Google would put \"+\" between the words instead of spaces, so I'll do that too.\n",
    "\n",
    "for pair in search:\n",
    "    pair[\"govt\"] = pair[\"govt\"].replace(\" \", \"+\") #Replace spaces with +s.\n",
    "    pair[\"group\"] = pair[\"group\"].replace(\" \", \"+\")\n",
    "    \n",
    "search[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to loop through the dictionaries and get the URLs to Google each pair,\n",
    "plus \"Wikipedia\" to get the Wikipedia links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.google.com/search?sclient=psy-ab&client=ubuntu&hs=k5b&channel=fs&biw=1366&bih=648&noj=1&q=Popular+Revolutionary+Movement+Bolivia+Wikipedia',\n",
       " 'https://www.google.com/search?sclient=psy-ab&client=ubuntu&hs=k5b&channel=fs&biw=1366&bih=648&noj=1&q=MNR+Bolivia+Wikipedia',\n",
       " 'https://www.google.com/search?sclient=psy-ab&client=ubuntu&hs=k5b&channel=fs&biw=1366&bih=648&noj=1&q=ELN+Bolivia+Wikipedia',\n",
       " 'https://www.google.com/search?sclient=psy-ab&client=ubuntu&hs=k5b&channel=fs&biw=1366&bih=648&noj=1&q=Khmer+Issarak+France+Wikipedia',\n",
       " 'https://www.google.com/search?sclient=psy-ab&client=ubuntu&hs=k5b&channel=fs&biw=1366&bih=648&noj=1&q=Peoples+Liberation+Army+China+Wikipedia']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making a list of the Google URLS:\n",
    "\n",
    "urls = []\n",
    "\n",
    "for pair in search:\n",
    "    url = \"https://www.google.com/search?sclient=psy-ab&client=ubuntu&hs=k5b&channel=fs&biw=1366&bih=648&noj=1&q=\" + str(pair[\"group\"]) + \"+\" + str(pair[\"govt\"]) + \"+Wikipedia\"\n",
    "    #Don't ask me what all that stuff in the beginning of the URL is\n",
    "    #because i have no idea; the internet told me to put it there.\n",
    "    #It doesn't work with just the \"https://www.google.com/#q=\" from class.\n",
    "    urls.append(url)\n",
    "\n",
    "#Test:\n",
    "urls[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I first tried looping through the URLs and saving the first response, there were 5-10 of them that were breaking the loop because of strange characters in the URL.  It turned out that in the dataset I was using, accent marks had been replaced by blank spaces, deleting the letter as well as the accent mark.  I changed these by hand in the csv file to the names that they were supposed to be.  I couldn't think of any way to code this because since the original letter was deleted, you had to know what the group was actually called in order to correct it (couldn't just remove accent marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now, loop through the URLs and save the server responses, as text and parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gRes = []\n",
    "\n",
    "for url in urls:\n",
    "    res = requests.get(url) #GET request\n",
    "    res_text = res.text #Save response as text\n",
    "    res_parse = BeautifulSoup(res_text, \"html.parser\") #Parse results\n",
    "    gRes.append(res_parse) #Save parsed results in the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gRes) #Hooray!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how to get just the first link out of this?  It looks like a mess.\n",
    "Luckily Google uses the tag \"cite\" for links, so can just look for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'https://en.wikipedia.org/wiki/Revolutionary_Nationalist_Movement',\n",
       " u'https://en.wikipedia.org/wiki/Revolutionary_Nationalist_Movement',\n",
       " u'https://en.wikipedia.org/wiki/ELN',\n",
       " u'https://en.wikipedia.org/wiki/Khmer_Issarak',\n",
       " u\"https://en.wikipedia.org/wiki/People's_Liberation_Army\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_links = [] #blank list to store links\n",
    "\n",
    "for result in gRes:\n",
    "    first_link = result.select(\"cite\")[0].text #This gets the first link and saves it as text.\n",
    "    first_links.append(first_link) #add links to list\n",
    "\n",
    "first_links[0:5] #Awesome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Added this later because I realized that the CSV wouldn't save without it!\n",
    "Links = []\n",
    "\n",
    "for link in first_links:\n",
    "    Links.append(link.encode(\"utf8\"))\n",
    "\n",
    "len(Links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to make a list of dictionaries, in which each dictionary has the group name, the government, and first link.  Right now, the first links and the list of dictionaries I used to search for them are the same lenght and in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'govt': 'United+Kingdom',\n",
       "  'group': 'Mau+Mau',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Mau_Mau_Uprising'},\n",
       " {'govt': 'Cuba',\n",
       "  'group': 'Military+Faction+-+26th+of+July+Movement',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/26th_of_July_Movement'},\n",
       " {'govt': 'Cuba',\n",
       "  'group': 'Military+Faction+-+26th+of+July+Movement',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/26th_of_July_Movement'},\n",
       " {'govt': 'Cuba',\n",
       "  'group': 'National+Revolutionary+Council',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Cuban_Revolutionary_Council'},\n",
       " {'govt': 'Indonesia',\n",
       "  'group': 'Darul+Islam+Movement',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Darul_Islam_(Indonesia)'},\n",
       " {'govt': 'Indonesia',\n",
       "  'group': 'Darul+Islam+Movement',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Darul_Islam_(Indonesia)'},\n",
       " {'govt': 'Indonesia',\n",
       "  'group': 'PRRI',\n",
       "  'wiki_link': 'https://id.wikipedia.org/wiki/Pemerintahan_Revolusioner_Republik_ Indonesia'},\n",
       " {'govt': 'Indonesia',\n",
       "  'group': 'Permesta+movement',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Permesta'},\n",
       " {'govt': 'France',\n",
       "  'group': 'Istiqlal',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Istiqlal_Party'},\n",
       " {'govt': 'France',\n",
       "  'group': 'National+Liberation+Army',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/National_Liberation_Army_(Algeria)'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigList = []\n",
    "\n",
    "for i in range(len(Links)): #Loop through links\n",
    "    dictionary = {} #Create an empty dictionary\n",
    "    dictionary[\"wiki_link\"] = Links[i] #adds Wiki link to dictionary\n",
    "    dictionary[\"group\"] = search[i][\"group\"] #adds group name\n",
    "    dictionary[\"govt\"] = search[i][\"govt\"] #adds government\n",
    "    bigList.append(dictionary) #adds dictionary for each group to the list\n",
    "\n",
    "\n",
    "bigList[100:110] #yes it's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's save this so that I don't have to run this code anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = bigList[0].keys() # get a list of the keys, which will be column names.\n",
    "with open('BigList.csv', 'wb') as output_file:\n",
    "     dict_writer = csv.DictWriter(output_file, keys)\n",
    "     dict_writer.writeheader()\n",
    "     dict_writer.writerows(bigList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we'll open the CSV as bigList again so that if anything goes wrong, I can restart from this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigList = []\n",
    "\n",
    "with open(\"BigList.csv\", \"rU\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        bigList.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'govt': 'Bolivia',\n",
       "  'group': 'MNR',\n",
       "  'ideologies': \"[u'Nationalism', u'Populism']\",\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Revolutionary_Nationalist_Movement'},\n",
       " {'govt': 'Bolivia',\n",
       "  'group': 'ELN',\n",
       "  'ideologies': '',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/ELN'},\n",
       " {'govt': 'France',\n",
       "  'group': 'Khmer+Issarak',\n",
       "  'ideologies': '',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Khmer_Issarak'},\n",
       " {'govt': 'China',\n",
       "  'group': 'Peoples+Liberation+Army',\n",
       "  'ideologies': '',\n",
       "  'wiki_link': \"https://en.wikipedia.org/wiki/People's_Liberation_Army\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigList[1:5] #good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a function that will take each of the URLs in the list as inputs and then take the contents of the box in the upper right hand corner of the Wiki page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wiki_ideo(URL):\n",
    "    if \"https://en.wikipedia.org/wiki\" in URL: #Make sure it's a Wikipedia link.\n",
    "        soup = BeautifulSoup(requests.get(URL).text) #make a get request, read as text, soup it\n",
    "    \n",
    "        if \"infobox vcard\" in str(soup): #this makes sure the page has the box in the right corner\n",
    "            table = soup.select(\"table.infobox.vcard\")[0] #Looking at the box in the right corner\n",
    "            rows = table.select(\"tr\") #Getting the rows.\n",
    "    \n",
    "    #The part below loops through the row, and if ideology is in the row, then it saves the\n",
    "    #links in the row, which will be the values of \"ideology.\"  Then it takes the text of\n",
    "    #those links and returns them.\n",
    "    \n",
    "            for row in rows:\n",
    "                if \"Ideology\" in row.text:\n",
    "                    ideology = row\n",
    "                    if \"category\" in str(ideology):\n",
    "                        keywords = ideology.select(\"td.category\")\n",
    "                        links = keywords[0].select(\"a\")\n",
    "                        words = [link.text for link in links]\n",
    "                        return words #List of ideologies associated with group.\n",
    "\n",
    "#The if statements are because it just kept breaking when it ran across pages that were\n",
    "#ormatted differently and/or were the wrong pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Nationalism', u'Populism']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_ideo(bigList[0][\"wiki_link\"])\n",
    "#Okay, it works for one of them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now loop through all the dictionaries in the list.\n",
    "\n",
    "for dictionary in bigList: #loop through dictionaries for each group\n",
    "    page = dictionary[\"wiki_link\"] #use Wiki page for group\n",
    "    ideologies = [] #blank list for ideologies as there tend to be several\n",
    "    ideologies = wiki_ideo(page) #use the function that gets the ideologies from the wiki page\n",
    "    dictionary[\"ideologies\"] = ideologies #save a new key ideologies with value of group's ideos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'govt': 'Bolivia',\n",
       " 'group': 'Popular+Revolutionary+Movement',\n",
       " 'ideologies': [u'Nationalism', u'Populism'],\n",
       " 'wiki_link': 'https://en.wikipedia.org/wiki/Revolutionary_Nationalist_Movement'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(bigList)\n",
    "bigList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right.  So the good news is - it works!  And the bad news is... as we'll soon see, most of the Wikipedia pages don't have the box in the corner with ideology in it, so it didn't work for a lot of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I wrote another CSV and opened it again as a checkpoint here because\n",
    "#I kept accidentally overwriting things and having to start over.\n",
    "\n",
    "keys = bigList[0].keys()\n",
    "with open('ideo-data.csv', 'wb') as output_file:\n",
    "     dict_writer = csv.DictWriter(output_file, keys)\n",
    "     dict_writer.writeheader()\n",
    "     dict_writer.writerows(bigList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'govt': 'Bolivia',\n",
       " 'group': 'Popular+Revolutionary+Movement',\n",
       " 'ideologies': \"[u'Nationalism', u'Populism']\",\n",
       " 'wiki_link': 'https://en.wikipedia.org/wiki/Revolutionary_Nationalist_Movement'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigList = []\n",
    "\n",
    "with open(\"ideo-data.csv\", \"rU\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        bigList.append(row)\n",
    "\n",
    "bigList[0] #good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have a bunch of lists of ideologies, but many of them are too specific to be useful for analysis.  For example, we want \"Kurdish Nationalism\" to be just \"Nationalism,\" and we want to group \"Marxism,\" \"Leninism,\" and \"Communism\" together.\n",
    "\n",
    "<u> Coding rules </u>\n",
    "\n",
    "Major ideologies:\n",
    "\n",
    "-Any group/country/region nationalism, independence, separatism, or self-determination will get a 1 for nationalism\n",
    "\n",
    "-Anything with Marxism, Leninism, Maoism, or Communism will get a 1 for communist.\n",
    "\n",
    "-Anything with Islamism, sect of Islam, or clericalism gets a 1 for Islamist.\n",
    "\n",
    "-Anything democracy gets 1 for democracy\n",
    "\n",
    "Ignoring the rest for now, as there are not many observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Communist': 0,\n",
       " 'Democracy': 0,\n",
       " 'Islamist': 0,\n",
       " 'Nationalist': 1,\n",
       " 'govt': 'Bolivia',\n",
       " 'group': 'Popular+Revolutionary+Movement',\n",
       " 'ideologies': \"[u'Nationalism', u'Populism']\",\n",
       " 'wiki_link': 'https://en.wikipedia.org/wiki/Revolutionary_Nationalist_Movement'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dictionary in bigList:\n",
    "    ideologies = dictionary[\"ideologies\"]\n",
    "    \n",
    "    #Checking for nationalisms.\n",
    "    if \"ationalism\" in ideologies:\n",
    "        #Taking off the first letter for capitalization\n",
    "        #and the end to allow for variants\n",
    "        dictionary[\"Nationalist\"] = 1\n",
    "    \n",
    "    elif \"ndependence\" in ideologies:\n",
    "        dictionary[\"Nationalist\"] = 1\n",
    "    \n",
    "    elif \"eparatis\" in ideologies:\n",
    "        dictionary[\"Nationalist\"] = 1\n",
    "    \n",
    "    elif \"self-determin\" in ideologies:\n",
    "        dictionary[\"Nationalist\"] = 1\n",
    "    \n",
    "    else:\n",
    "        dictionary[\"Nationalist\"] = 0\n",
    "    \n",
    "    #Checking for communisms.\n",
    "    if \"ommunis\" in ideologies:\n",
    "        dictionary[\"Communist\"] = 1\n",
    "    \n",
    "    elif \"arxis\" in ideologies:\n",
    "        dictionary[\"Communist\"] = 1\n",
    "    \n",
    "    elif \"eninis\" in ideologies:\n",
    "        dictionary[\"Communist\"] = 1\n",
    "    \n",
    "    elif \"Mao\" in ideologies:\n",
    "        dictionary[\"Communist\"] = 1\n",
    "    \n",
    "    else:\n",
    "        dictionary[\"Communist\"] = 0\n",
    "    \n",
    "    #Checking for Islamism.\n",
    "    if \"slamis\" in ideologies:\n",
    "        dictionary[\"Islamist\"] = 1\n",
    "    \n",
    "    elif \"Sunni\" in ideologies:\n",
    "        dictionary[\"Islamist\"] = 1\n",
    "    \n",
    "    elif \"Shia\" in ideologies:\n",
    "        dictionary[\"Islamist\"] = 1\n",
    "    \n",
    "    elif \"lericalis\" in ideologies:\n",
    "        dictionary[\"Islamist\"] = 1\n",
    "    \n",
    "    else:\n",
    "        dictionary[\"Islamist\"] = 0\n",
    "    \n",
    "    #Checking for democracy\n",
    "    if \"emocra\" in ideologies:\n",
    "        dictionary[\"Democracy\"] = 1\n",
    "    \n",
    "    else:\n",
    "        dictionary[\"Democracy\"] = 0\n",
    "\n",
    "bigList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Update the CSV.\n",
    "\n",
    "keys = bigList[0].keys()\n",
    "with open('ideo-data.csv', 'wb') as output_file:\n",
    "     dict_writer = csv.DictWriter(output_file, keys)\n",
    "     dict_writer.writeheader()\n",
    "     dict_writer.writerows(bigList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Because I didn't wind up with enough cases to do the analysis, I am instead going to webscrape the content of the Wikipedia pages for the cases that did work, and do some text analysis on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Communist': '0',\n",
       "  'Democracy': '0',\n",
       "  'Islamist': '0',\n",
       "  'Nationalist': '1',\n",
       "  'govt': 'Bolivia',\n",
       "  'group': 'MNR',\n",
       "  'ideologies': \"[u'Nationalism', u'Populism']\",\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/Revolutionary_Nationalist_Movement'},\n",
       " {'Communist': '0',\n",
       "  'Democracy': '0',\n",
       "  'Islamist': '0',\n",
       "  'Nationalist': '0',\n",
       "  'govt': 'Bolivia',\n",
       "  'group': 'ELN',\n",
       "  'ideologies': '',\n",
       "  'wiki_link': 'https://en.wikipedia.org/wiki/ELN'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restarted the kernal again and had to open the data again.\n",
    "\n",
    "bigList = []\n",
    "\n",
    "with open(\"ideo-data.csv\", \"rU\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        bigList.append(row)\n",
    "\n",
    "bigList[1:3] #good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, I only want to use the ones with the ideology field, so let's put those in their own list.\n",
    "\n",
    "shortList = []\n",
    "\n",
    "for group in bigList:\n",
    "    if group[\"ideologies\"] != \"\":\n",
    "        shortList.append(group)\n",
    "    \n",
    "    \n",
    "#shortList[0:15] #good\n",
    "len(shortList)\n",
    "\n",
    "#Only 126 of 578 :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now I'm going to webscrape again, but this time for the content of the Wikipedia page.\n",
    "\n",
    "def wiki_content(URL):\n",
    "    if \"https://en.wikipedia.org/wiki\" in URL: #Make sure it's a Wikipedia link.\n",
    "        soup = BeautifulSoup(requests.get(URL).text) #make a get request, read as text, soup it\n",
    "        if \"mw-content\" in str(soup): #makes sure the page is set up in the same way\n",
    "            #print URL\n",
    "            content = soup.select(\"div.mw-content-ltr\")[0].text #gets the content\n",
    "            return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wiki_content(shortList[0][\"wiki_link\"])\n",
    "#Okay, so it works for one of them.  Now to loop through them all and save the content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I don't know why this happened, but I have to get rid of the ones with this\n",
    "#weird series of characters because otherwise they break the function.\n",
    "\n",
    "for dictionary in shortList:\n",
    "    if \"\\xe4\\xf3\\xf1\" in dictionary[\"wiki_link\"]:\n",
    "        shortList.remove(dictionary)\n",
    "\n",
    "for dictionary in shortList:\n",
    "    if \"Mart\\xed\" in dictionary[\"wiki_link\"]:\n",
    "        shortList.remove(dictionary)\n",
    " \n",
    "for dictionary in shortList:\n",
    "    if \"C\\xed\\xc7te\" in dictionary[\"wiki_link\"]:\n",
    "        shortList.remove(dictionary)\n",
    "\n",
    "for dictionary in shortList:\n",
    "    if \"\\xe4\\xf3\\xf1\" in dictionary[\"wiki_link\"]:\n",
    "        shortList.remove(dictionary)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#len(shortList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dictionary in shortList:\n",
    "    page = dictionary[\"wiki_link\"]\n",
    "    contents = wiki_content(page).encode(\"utf8\")\n",
    "    dictionary[\"content\"] = contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shortList[0:2] #works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove \\n and \\r, which are messing with CSV formatting.\n",
    "\n",
    "\n",
    "for dictionary in shortList:\n",
    "    dictionary[\"content\"] = dictionary[\"content\"].replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "for dictionary in shortList:\n",
    "    dictionary[\"content\"] = dictionary[\"content\"].replace(\"\\r\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Export to CSV.\n",
    "\n",
    "keys = shortList[0].keys()\n",
    "with open('content-ideo.csv', 'wb') as output_file:\n",
    "     dict_writer = csv.DictWriter(output_file, keys)\n",
    "     dict_writer.writeheader()\n",
    "     dict_writer.writerows(shortList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The end!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
